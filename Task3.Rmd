---
title: "Task3 - Multiple Regression in R"
author: "Zaily Lopez"
date: "8/8/2019"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**PROBLEM DEFINITION**

You have been asked by Danielle Sherman, CTO of Blackwell Electronics, to predict the sales in four different product types while assessing the effects service and customer reviews have on sales. You'll be using Regression to build machine learning models for this analyses using a choice of two of three popular algorithms. Once you have determined which one works better on the provided data set, Danielle would like you to predict the sales of four product types from the new products list and prepare a report of your findings.

This task requires you to prepare one deliverable for Danielle Sherman:

Sales Prediction Report. A report in a Zip file that includes:
A brief summary in Word or PowerPoint of your methods and results that include:
The algorithms you tried. 
The algorithm you selected to make the predictions, including a rationale for selecting the method you did and the level of confidence in the predictions.
Your sales predictions for four target product types found in the new product attributes data set
A chart that displays the impact of customer and service reviews have on sales volume. 
The results of each model you constructed, exported from R
The steps in the following tabs will walk you through this process.



**DATA PRE-PROCESS**

```{r}


#install.packages("corrplot")


library(caret)
library(corrplot)
library(RColorBrewer)


#set the directory
setwd ('C:\\Users\\zailylop\\Documents\\RStudio\\PROJECTS\\R') 


##I already set the data set with the types of variables with the colClasses parameter
raw.data.set <- read.csv('existingproductattributes2017.csv', header = T)
new.data.set <- read.csv("newproductattributes2017.csv", header = T,
                    colClasses = c("factor", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric" )) 


# dummify the data
process.data.set <- dummyVars(" ~ .", data = raw.data.set)
process.data.set



ds <- data.frame(predict(process.data.set, newdata = raw.data.set))
ds

str(ds)
summary (ds)

#Remove Na values for the BestSellersRank Column 
ds$BestSellersRank  <- NULL  #to remove the the column from the ds. 

#str(gbm_predict_incomplete_prob)
head (ds, 10)

str(ds)
summary (ds)


corrData <- cor(ds)
corrData

# Create a color palette
palette <- brewer.pal(8, "Accent")

cp <- corrplot(corrData, method = "circle", order = "AOE", tl.col="Black", tl.cex=0.7 )

```




**DATA TRANSFORMATION**

```{r}



set.seed(222) 
data.train <- createDataPartition (y = ds$Volume,
                                   ## the outcome data are needed 
                                   p = .75,  ##75% Will be use for training. 
                                   ## The percentage of data in the training set 
                                   list = FALSE) 
                                  

head (data.train)
str(data.train)
 
training <- ds[ data.train,] 
testing <- ds[-data.train,] 

nrow(training)      
nrow(testing)  

summary (training)
summary (testing)
 


```





**REGRESSION MODELS**

Using the steps in 'R Walkthrough' that outlined train a linear model, create a linear model that uses volume as its dependent variable. 
Use the summary() function of R to evaluate the model and make a specific note of the R-Squared value.



```{r}



#Testing with some variables - for a Lineal Model 
set.seed(222)

# Testing with one depandant  and one independant variable. 
m1.lm <- lm(Volume~ x1StarReviews, training)
summary (m1.lm)
plot (m1.lm, col= palette)


m2.lm <- lm(Volume~ x3StarReviews, training)
summary (m2.lm)
plot (m2.lm, col= palette)


m3.lm <- lm(Volume~ PositiveServiceReview, training)
summary (m3.lm)
plot (m3.lm, col= palette)


m4.lm <- lm(Volume~ Recommendproduct, training)
summary (m4.lm)
plot (m4.lm, col= palette)



```




1. Did the model perform well? 

Answer:Not very good with a Simple Linear Regression iwith one independent variable and one dependent variable.



2. Why or why not? 
Answer: R square, Adjusted R-squared, P-Value are very low. We don't have a normal distribution for these variable. With non parametrics will not assume a normal distribution. Data is little more complex. 

#R² measures, “How much the change in output variable (y) is explained by the change in input variable(x).
#R-squared is always between 0 and 1
#In general, higher the R², more robust will be the model. 


#Adjusted R-squared should always be used with models with more than one predictor variable.
#It is interpreted as the proportion of total variance that is explained by the model.

#Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). 


**Other testing**

```{r}

#multiple regression model
m5.lm <- lm(Volume~ ., training)
summary (m5.lm)
#plot (m5.lm, col=palette)


m7.lm <- lm(Volume ~ x2StarReviews + x3StarReviews + x5StarReviews + ProductType.Accessories + ProductType.Laptop + ProductType.PC + ProductNum,  training)
summary (m7.lm)

#to avoid Multicollinearity eliminate (x5StarReviews or x4StarReviews) and (x1StarReviews or x2StarReviews)



```



**#1. CARET - SVM**
```{r}

#1. CARET - SVM

fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 2)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
set.seed(222)
svm1.model <- train(Volume ~ x5StarReviews + PositiveServiceReview, 
                data = training, 
                method = "svmLinear", 
                trControl=fitControl, 
                tuneLength = 10)
#training result
svm1.model


##overfitted model ?
######VALIDATION OF THE MODEL 
svm1_predict <- predict (svm1.model, testing) 
str(svm1_predict)
svm1_predict







```




**#2. CARET - RANDOM FOREST**
```{r}

#2. CARET - RANDOM FOREST 


fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 2)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
set.seed(222)
rf.model <- train(Volume ~ x5StarReviews + PositiveServiceReview, 
                data = training, 
                method = "rf", 
                trControl=fitControl, 
                tuneLength = 3)
#training result
rf.model



######VALIDATION OF THE MODEL 
rf_predict <- predict (rf.model, testing) 
str(rf_predict)




```



**#3. CARET - Gradient Boosting**

```{r}

#3. CARET - Gradient Boosting

grid <- expand.grid(interaction.depth = seq(1, 7, by = 2), #number of depth sequence
                    n.trees = seq(100, 200, by = 50),  #number of trees
                    shrinkage = c(0.01, 0.1), # slow learner and fast learner on the shrinkage
                    n.minobsinnode = c(3,5)
                    )


fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 2)

set.seed(222)
gbm.model <- train ( Volume~ x5StarReviews + PositiveServiceReview , 
                   data = training, 
                   method = "gbm",
                   tuneGrid = grid,
                   verbose = FALSE,
                   trControl = fitControl
                   )

gbm.model

summary(gbm.model)

######VALIDATION OF THE MODEL 
gbm_predict <- predict (gbm.model, testing) 
str(gbm_predict)
summary(gbm_predict)





```





**Compare all the models**
```{r}

#COMPARE MODELS 
all.models <- list(SVM1=svm1.model, 
                   RandomFores1=rf.model,              #second best  
                   GradientBoosting=gbm.model        #first best 
                   )

comp.models <- resamples(all.models) 

summary(comp.models$values)
summary(comp.models)  #accuracy


#MAE: Mean absolute error: measures the average magnitude of the errors in a set of predictions, without considering their direction.  
#Root mean squared error (RMSE): RMSE is a quadratic scoring rule that also measures the average magnitude of the error. It’s the square root of the average of squared differences between prediction and actual observation. 
#FOR BOTH lower values are better.


# Rsquared : R-squared is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression.
# FOR THE Rsquared: he higher the R-squared, the better the model fits your data. 



```






**Add predictions to the new products data set**
```{r}

#==============================

svm1 <- new.data.set 
rf <-   new.data.set 
gbm <-  new.data.set

svm1_predict <- predict (svm1.model, svm1) #MAYBE WILL BE OVERFIT?
rf_predict   <- predict (rf.model,   rf) #SECOND BEST BUT WILL BE THE "BEST ONE" ?
gbm_predict  <- predict (gbm.model,  gbm) 

 



svm1$Volume <- svm1_predict
rf$Volume   <- rf_predict
gbm$Volume  <- gbm_predict
  
write.csv(svm1, file="SVM_Output.csv", row.names = TRUE)
write.csv(rf, file="RF_Output.csv", row.names = TRUE)
write.csv(gbm, file="GBM_Output.csv", row.names = TRUE)



```






**REPORT**

1. Did you learn anything of potential business value from this analysis?

Answer: Not all the models will fit to solve the different business problems. 



2. Was it straightforward to rerun your projections of sales volume using both models? 

Answer: Yes, but is hard to understand the entire subject without explanation. 



3. What are the main lessons you've learned from this experience?

Answer: Well, google is your friend! use it ... 



4. What recommendations would you give to the sales department regarding your findings relating to the different types of reviews? 

Answer: According to the best model the focus should be the Laptop and the Netbook, those will be the higher sales - products. 



